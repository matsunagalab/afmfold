\section{Related Work}
\label{sec:related}

Generative AI-based approaches employing diffusion models or flow models enable us to efficiently sample molecular conformations in multiscale manners. For example, recent structure-generation foundation models, including \AFiii and \Boltzi, employ diffusion-based formulations. In particular, \Boltzii \cite{passaro2025boltz2} introduced \emph{boltz-steering}, a framework that imposes a customized potential to navigate the sampling towards physically plausible conformations. These models largely follow a ``one sequence--one structure'' paradigm, which do not focus on producing diverse conformational ensembles or capturing conformational flexibilities. 

Several approaches have been proposed to address this problem. For example, the MSA subsampling technique \cite{delAlamo2022sampling} and its extensions \cite{Wayment-Steele2023MSAClustering, daSilva2024_subsampledAF2, KalakotiWallner2025_AFsample2} increase the diversity of multiple sequence alignments (MSAs) by masking parts of the MSA. 
%While these approaches can improve diversity in certain systems, the relationship between perturbations in the MSA and the resulting structural diversity would be unclear. The observed structural diversity is not guaranteed to follow the thermodynamic stability dictated by the real Boltzmann distribution.
Another powerful direction is the development of ensemble generative or MD surrogate models. An early contribution in this area is the Boltzmann generator \cite{NoeOlssonKohlerWu2019_BoltzmannGenerators}, which was designed to learn and reproduce the Boltzmann distribution of small, specific peptides. More recently, models have been developed to generate diverse structural ensembles from sequences by learning from extensive MD simulation data across a wide range of proteins \cite{jing2023eigenfold, jing2024alphaflow, Zheng2024_DiG_NatMachIntell, Cheng2024_AlphaFolding, Jing2024mdgen, jin2025p2dflow, bioemu2025}. In these methods, obtaining sufficiently long MD trajectories for training requires substantial computational resources, and such models inevitably inherit the force-field biases present in the training data. 
%One promising alternative is to leverage experimental data as training data sets, which offers a pathway to develop ensemble generators that are grounded in experimental observations rather than computational approximations.

To mitigate this issue, recent studies have explored conditioning ensemble generative models on experimental measurements or physical prior knowledge. Examples include methods that generate NMR-consistent structural ensembles \cite{maddipatla2025inverse, Liu2024_EGDiff, Liu2025_ExEnDiff}, and cryoEM-consistent modelig using \Boltzi and Chroma \cite{raghu2025multiscale, levy2025solving}. Following this direction, \Model enables AFM-conditioned conformation generation, guiding \AFiii's prior distribution toward modeling more dynamic conformational states captured in HS-AFM images.

%To estimate 3D structures from AFM images, approaches such as flexible fitting \cite{Niina2020} and NMFF-AFM \cite{Wu2024, amyot_flexible_2025} find conformations that reproduce images with a high correlation coefficient (c.c.) with the reference AFM image. While effective, the flexible fitting depends on long time-comsuming simulations while NMFF-AFM is limited to capturing only harmonic fluctuations around a single reference structure. 

