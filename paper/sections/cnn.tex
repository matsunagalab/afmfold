\subsection{Group-equivariant CNNs}
\label{subsec:se2cnn}

% --- Setup/context ---
%Unlike many other problems, reconstructing 3D conformations from AFM images requires verifying whether the 3D structures generated by \AFiii are consistent with a given 2D reference image. The generation process of \AFiii is guided to maximize the resulting likelihood, thereby producing conformations that agree closely with AFM images (as explained in \cref{subsec:guided-diffusion}). However, because the orientation of the molecule in the reference image is unknown and may correspond to any element of the full 3D rotation group, a naive search for the ground-truth pose is computationally prohibitive. Thus, an effective strategy is needed to assess the agreement between 2D AFM images and 3D molecular conformations. In particular, rather than transforming conformations into the AFM image format—which is computationally demanding due to the rotational degrees of freedom—it is more practical to derive features from AFM images that are more readily accessible from the conformational side. 

In AFM 2D image analysis, similar to single particle analysis of cryo-EM micrographs, the pose of the 3D structure is unknown. The alignment calculation between a 2D image and the 3D structural pose requires an exhaustive search and is computationally expensive. Moreover, if misalignment occurs, it leads to extreme deterioration in estimation accuracy. In the case of cryo-EM, the influence of misalignment could be mitigated on average by a vast number of micrographs, but in the case of HS-AFM, since we want to perform structural estimation for each single image to infer underlying conformational dynamics, misalignment cannot be tolerated. 
Therefore, we use a rotation-equivariant CNN model (\emph{group-equivariant} CNN; g-CNN) \cite{CohenWelling2016_GCNN, CohenWelling2017_SteerableCNNs, e2cnn, WeilerEtAl2018_3DSteerableCNNs} that directly estimates structure-related CVs from 2D AFM images without performing alignment calculations. 
%To mitigate the sensitivity to alignment, we introduce an approach that estimates structure-related CVs directly from 2D AFM images, without requiring alignment. For this purpose, we employ a rotation-equivariant CNN (\emph{group-equivariant} CNN; g-CNN) \cite{CohenWelling2016_GCNN, CohenWelling2017_SteerableCNNs, e2cnn, WeilerEtAl2018_3DSteerableCNNs}, which is known to achieve high data efficiency by constraining the hypothesis space through rotational symmetry.

In navigating the structure generation process of \AFiii to generate 3D structures consistent with AFM images, it would be possible to optimize by calculating image similarity at each step, as done in rigid-body fitting. 
In this case, higher-resolution image reproduction is expected, but on the other hand, we empirically found that it tends to produce structures trapped in local minima. This behavior arises because the image similarity landscape is highly multimodal and extremely sensitive to translational and in-plane rotational differences. Under a feasible amount of alignment search, inaccurate gradients are continuously applied, resulting in misleading forces during optimization. 
Therefore, instead of relying on image-to-image correlation, it was necessary to construct a comparison measure that is robust to in-plane rotations and translations of AFM images. In particular, to handle a large number of AFM frames, the similarity between the generated intermediate structures and the images needed to be computed efficiently.
%Therefore, in this study, we decided that our g-CNN model estimates low-dimensional CVs (such as inter-domain distances in the case of multi-domain proteins) and uses them for structure generation in \AFiii.

With this motivation in mind, we summarize the theory of \gcnn \cite{CohenWelling2016_GCNN, CohenWelling2017_SteerableCNNs, e2cnn, WeilerEtAl2018_3DSteerableCNNs}, and describe how it enables efficient estimation of CVs from AFM images. A standard CNN is naturally \emph{translation equivariant} but not rotation equivariant. In contrast, \gcnn modifies feature indexing and kernel weight sharing so that the entire network becomes equivariant with respect to a chosen rotation group. Utilizing this architecture, the same physical state yields an identical representation regardless of its placement on the image plane, thereby reducing the need for extensive data augmentation and shortening training time. Consequently, we employ the \gcnn to estimate CVs from a single AFM image.

%\paragraph{Translation equivariance}
We model an AFM image as a single-channel (scalar) field $I:\mathbb{R}^2\to\mathbb{R}$ with pixel coordinate $x=(x_1,x_2)\in\mathbb{R}^2$. 
In a standard CNN, intermediate feature maps are represented as functions $f:\mathbb{R}^2 \to \mathbb{R}^c$.
The input image is first mapped to a $c$-channel field by convolution with channel-specific filters $\{\psi_i\}_{i=1}^c$:
\begin{equation}
    (\psi * I)(x)[i] := \int_{\mathbb{R}^2} \psi_i(y)\, I(x - y)\, dy,
    \label{eq:lifting}
\end{equation}
where $*$ is convolution and $dy$ denotes the area element. 
In practice, the integral is implemented as a finite sum over pixels; we keep the continuous notation for clarity.

% --- Group and action for standard fields ---
Here, we consider the planar motion group $\R^2 \rtimes C_N$, where $C_N=\{e,r,\dots,r^{N-1}\}\subset \mathrm{SO}(2)$ is a finite rotation subgroup.
For scalar or standard $c$-channel fields (without group indexing that we later explain), 
the action $\pi(t,g)$ of translation $t\in\R^2$ and rotation $g\in C_N$ for the field $u$ is $(\pi(t,g)u)(x)\;:=\;u\big(g^{-1}(x-t)\big)$.

Because convolution commutes with translations, a standard CNN is translation-equivariant. 
For a single convolution with a (matrix-valued) kernel $k(y)\in\R^{c_{\mathrm{out}}\times c_{\mathrm{in}}}$,
\begin{equation}
    \begin{aligned}
        \big(k * (\pi(t,e) u)\big)(x) 
        &= \int_{\mathbb{R}^2} k(y)\, u(x-y-t)\, dy \\
        &= (k * u)(x - t) = \big(\pi(t,e) (k * u)\big)(x).
    \end{aligned}
    \label{eq:trans-equiv}
\end{equation}
Since a typical activation $\sigma$ is pointwise, $\sigma$ is also translation-equivariant, $\sigma (\pi(t, e) u) = \pi(t, e) \sigma (u)$ and the property propagates through the network. By contrast, the standard convolution is generally \emph{not} rotation-equivariant.

%\paragraph{Rotation equivariance}
The key idea of \gcnns is to \emph{lift} an image to a feature field indexed by group elements and to impose weight sharing consistent with the group action.
Given a base filter $\psi:\mathbb{R}^2\to\mathbb{R}$, define its rotated copies $\psi_h(y):=\psi(h^{-1}y)$ for $h\in C_N$, and set
\begin{equation}
    v(x)[h] \;:=\; \int_{\mathbb{R}^2} \psi(h^{-1}y)\, I(x-y)\, dy,
    \qquad h\in C_N.
    \label{eq:gcnn-lifting}
\end{equation}
Thus $v:\mathbb{R}^2\times C_N\to\mathbb{R}$ is a group-indexed (orientation-channel) field.

% --- Equivariance statement (concise) ---
For such lifted fields, if the kernel satisfies the following constraint about sharing weights, $k(gy)[h,h'] = k(y) \big[g^{-1}h, g^{-1}h'\big]$ for all $g, h, h' \in C_N$, then the group convolution commutes with $\pi(0,g)$:
\begin{equation}
    \big(k * (\pi(0,g)v)\big)(x)[h] \;=\; \big(\pi(0,g)(k * v)\big)(x)[h].
    \label{eq:gcnn-rot-equiv}
\end{equation}
The proof can be found in Appendix D.1 of \cite{e2cnn}. 
Hence, adding to the translation equivariance \Cref{eq:trans-equiv}, we can construct CNNs equivariant to the chosen discrete rotation group $C_N$. 
Channel-wise activations commute with the orientation relabeling, so equivariance to rotations (and translations) is preserved layer by layer.

% --- Multi-block and pooling ---
A practical architecture uses multiple lifted blocks $v_1,\dots,v_b$; the overall action is the block-diagonal (direct-sum) representation $\pi=\bigoplus_{i=1}^b \pi_i$. In \Model, because we require a vector invariant to rotations and translations, we apply group pooling and spatial pooling per block at last; i.e.,
\begin{equation}
    \mathrm{GroupPooling}(v_i)(x) := \text{Max}_{h\in C_N} v_i(x)[h], \quad
    \mathrm{SpatialPooling}(v_i) := \text{Mean}_{x \in \R^2} v_i(x),
\end{equation}
which yields features invariant to translations and rotations.
